{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14baa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p /user/futurexskill/retailcust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f7868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put retailstore_large.csv /user/futurexskill/retailcust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5017cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 talentum supergroup   32024720 2023-11-27 15:20 /user/futurexskill/retailcust/retailstore_large.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/futurexskill/retailcust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46725173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "\n",
      "Logging initialized using configuration in jar:file:/home/talentum/hive/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: true\n",
      "OK\n",
      "Time taken: 3.066 seconds\n"
     ]
    }
   ],
   "source": [
    "!hive -e 'create database if not exists futurex;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2e2992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "\n",
      "Logging initialized using configuration in jar:file:/home/talentum/hive/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: true\n",
      "OK\n",
      "default\n",
      "futurex\n",
      "Time taken: 1.335 seconds, Fetched: 2 row(s)\n"
     ]
    }
   ],
   "source": [
    "!hive -e 'show databases;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use futurex;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop table if exists retailcustext_large purge;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266decbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create external table retailcustext_large (customerid INT, age INT, salary FLOAT,gender String,country String) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LOCATION '/user/futurexskill/retailcust/' TBLPROPERTIES (\"skip.header.line.count\"=\"1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed58c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from retailcustext_large limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b9269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: up [--level <n>| -n <levels>][--help][--version]   Report bugs to:  up home page: \r\n"
     ]
    }
   ],
   "source": [
    "!echo \"usage: up [--level <n>| -n <levels>][--help][--version] \\\n",
    "\\\n",
    "Report bugs to: \\\n",
    "up home page: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b862d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-c94581c36aec>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-c94581c36aec>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    hive -e 'show databases;'\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!echo 'hdfs dfs -mkdir -p /user/futurexskill/retailcust' > spark_hive_auto ;\n",
    "!echo 'hdfs dfs -put retailstore_large.csv /user/futurexskill/retailcust' >> spark_hive_auto ;\n",
    "!echo 'hdfs dfs -ls /user/futurexskill/retailcust\n",
    "!echo -e \"hive -e 'create database if not exists futurex;' \n",
    "hive -e 'show databases;'\n",
    "hive -e 'use futurex;' \n",
    "hive -e 'drop table if exists retailcustext_large purge;' \n",
    "hive -e 'create external table retailcustext_large (customerid INT, age INT, salary FLOAT,gender String,country String) ROW FORMAT DELIMITED FIELDS TERMINATED BY \",\" LOCATION '/user/futurexskill/retailcust/' TBLPROPERTIES ('skip.header.line.count'='1');' \n",
    "hive -e 'select * from retailcustext_large limit 10;' \" >> spark_hive_auto ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e5857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c04dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c210e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+------+-------+\n",
      "|customerid| age| salary|gender|country|\n",
      "+----------+----+-------+------+-------+\n",
      "|      null|null|   null|Gender|Country|\n",
      "|         1|  40|20000.0|  Male|Germany|\n",
      "|         2|  22|22000.0|Female| France|\n",
      "|         3|  57|24000.0|Female|England|\n",
      "|         4|  31| 2600.0|  Male|England|\n",
      "|         5|  57|50000.0|  Male| France|\n",
      "|         6|  41|35000.0|Female|England|\n",
      "|         7|  26| 4300.0|  Male|Germany|\n",
      "|         8|  30|32000.0|Female| France|\n",
      "|         9|  34|35000.0|  Male|Germany|\n",
      "|        10|  28|37000.0|Female| France|\n",
      "|        11|  76|25000.0|  Male|Germany|\n",
      "|        12|  53|27000.0|Female| France|\n",
      "|        13|  72|29000.0|Female|England|\n",
      "|        14|  27| 7600.0|  Male|England|\n",
      "|        15|  44|55000.0|  Male| France|\n",
      "|        16|  54|40000.0|Female|England|\n",
      "|        17|  21| 9300.0|  Male|Germany|\n",
      "|        18|  78|37000.0|Female| France|\n",
      "|        19|  73|40000.0|  Male|Germany|\n",
      "+----------+----+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[Table(name='newnew', database='default', description=None, tableType='MANAGED', isTemporary=False), Table(name='retailcustext_large', database='default', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='stocks_hbase', database='default', description=None, tableType=None, isTemporary=False), Table(name='test_table', database='default', description=None, tableType='MANAGED', isTemporary=False)]\n",
      "/user/hive/warehouse\n"
     ]
    }
   ],
   "source": [
    "# Here is the code for making connectivity to hive metastore from pyspark\n",
    "\n",
    "# spark = spark.builder.master('yarn').config('spark.sql.warehouse.dir', '/user/hive/warehouse').config('hive.metastore.uris', 'thrift://localhost:9083').enableHiveSupport().getOrCreate()\n",
    "# spark = spark.builder.master('yarn').enableHiveSupport().getOrCreate()\n",
    "# spark.sql(\"show databases\").show()\n",
    "# spark.sql(\"use futurex\").show()\n",
    "# spark.sql(\"show tables\").show()\n",
    "spark.table('futurex.retailcustext_large').show()\n",
    "print(spark.catalog.listTables())\n",
    "print(spark.conf.get('spark.sql.warehouse.dir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84339965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

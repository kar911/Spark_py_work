{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de212f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b126416",
   "metadata": {},
   "source": [
    "## Pyspark working with HBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303d3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this demo make sure to \n",
    "# 1 - install package happybase (~$ sudo pip3 install happybase)\n",
    "# 2 - start hbase and create stocks table (hbase> create 'stocks', 'info')\n",
    "# 3 - Start hbase thrift service (~$ hbase-daemon.sh start thrift)\n",
    "# Ref - https://blog.cloudera.com/how-to-use-the-hbase-thrift-interface-part-1/\n",
    "\n",
    "import happybase\n",
    "\n",
    "server = \"127.0.0.1\"\n",
    "table_name = \"stocks\"\n",
    "#table = happybase.Connection(server).table(table_name)\n",
    "#table.put(\"r1\", {\"info:c1\": \"v1\"})\n",
    "#table.put(\"r1\", {\"info:c2\": \"v2\"})\n",
    "#table.put(\"r1\", {\"info:c3\": \"v3\"})\n",
    "# truncate 'stocks' table \n",
    "# (hbase> truncate 'stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d53004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,open,high,low,close,volume,adjclose,symbol\n",
      "2000-07-18,144.8125,144.828125,141.4375,143.0,5.06836E7,50.155473,INTC\n",
      "2000-07-20,32.93751,34.25001,32.8125,33.75,3288300.0,8.789734,BEN\n",
      "2000-07-24,64.25,67.312477,64.187523,64.75,948800.0,7.689567,APH\n",
      "2000-07-26,21.875,22.125,20.9375,20.9375,1464300.0,15.61832,SHW\n",
      "2000-07-26,42.0,42.312481,41.625,41.875,1397600.0,9.402721,STJ\n",
      "2000-07-31,33.937519,33.999986,33.75,33.875011,273400.0,5.063753,GGP\n",
      "2000-08-07,41.375038,43.0,40.812481,42.812481,2.43376E7,4.869542,SBUX\n",
      "2000-08-09,55.562481,55.625,54.5,55.0,387600.0,10.495977,EQT\n",
      "2000-08-10,49.0,52.625,48.75,52.125,1511600.0,22.539051,BCR\n"
     ]
    }
   ],
   "source": [
    "# Load stocks.csv in an RDD.\n",
    "\n",
    "stocksRaw = sc.textFile(\"file:///home/talentum/test-jupyter/test/stocks.small.csv\")\n",
    "\n",
    "for r in stocksRaw.take(10):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b75a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-07-18,144.8125,144.828125,141.4375,143.0,5.06836E7,50.155473,INTC\n",
      "2000-07-20,32.93751,34.25001,32.8125,33.75,3288300.0,8.789734,BEN\n",
      "2000-07-24,64.25,67.312477,64.187523,64.75,948800.0,7.689567,APH\n",
      "2000-07-26,21.875,22.125,20.9375,20.9375,1464300.0,15.61832,SHW\n",
      "2000-07-26,42.0,42.312481,41.625,41.875,1397600.0,9.402721,STJ\n",
      "2000-07-31,33.937519,33.999986,33.75,33.875011,273400.0,5.063753,GGP\n",
      "2000-08-07,41.375038,43.0,40.812481,42.812481,2.43376E7,4.869542,SBUX\n",
      "2000-08-09,55.562481,55.625,54.5,55.0,387600.0,10.495977,EQT\n",
      "2000-08-10,49.0,52.625,48.75,52.125,1511600.0,22.539051,BCR\n",
      "2000-08-15,35.68749,35.68749,34.875,34.875,1246500.0,9.082726,BEN\n"
     ]
    }
   ],
   "source": [
    "# Create a new RDD by filtering out the header.\n",
    "stocks = stocksRaw.filter(lambda r: not r.startswith(\"date\"))\n",
    "for r in stocks.take(10):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a88c9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_insert(batch):\n",
    "    table = happybase.Connection(server).table(table_name) \n",
    "    for r in batch:\n",
    "        tokens = r.split(\",\")\n",
    "        key = tokens[0] + \"-\" + tokens[7]\n",
    "        value = {\"info:date\": tokens[0]\n",
    "                 ,\"info:open\": tokens[1]\n",
    "                 ,\"info:high\": tokens[2]\n",
    "                 ,\"info:low\": tokens[3]\n",
    "                 ,\"info:close\": tokens[4]\n",
    "                 ,\"info:volume\": tokens[5]\n",
    "                 ,\"info:adjclose\": tokens[6]\n",
    "                 ,\"info:symbol\": tokens[7]\n",
    "                }\n",
    "        # Look at jupyter console to see the print output\n",
    "        print(key, value)\n",
    "        table.put(key, value)\n",
    "   \n",
    "stocks.foreachPartition(bulk_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67c258fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/talentum/test-jupyter/test\n",
      "-----Creating Hive table on top of hbase----- \n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/talentum/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 2.3.6)\n",
      "Driver: Hive JDBC (version 2.3.6)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://localhost:10000/default> --drop table if exists stocks_hbase;\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "bname}.stocks_hbase(lhost:10000/default> CREATE EXTERNAL TABLE IF NOT EXISTS ${d \n",
      ". . . . . . . . . . . . . . . . . . . .>  key string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  `date` string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  open string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  high string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  low string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  close string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  volume string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  adjClose string,\n",
      ". . . . . . . . . . . . . . . . . . . .>  symbol string)\n",
      "e.hbase.HBaseSerDe' . . . . . . . . . .> ROW format serde 'org.apache.hadoop.hiv \n",
      ".HBaseSt. . . . . . . . . . . . . . . .> STORED BY 'org.apache.hadoop.hive.hbase orageHandler' \n",
      ":adjclose,info:sy . . . . . . . . . . .> WITH SERDEPROPERTIES('hbase.columns.map fo:date,info:open,info:high,info:low,info:close,info:volume,info mbol') \n",
      "ocks'); . . . . . . . . . . . . . . . .> TBLPROPERTIES ('hbase.table.name' = 'st \n",
      "No rows affected (0.339 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "rom dbc:hive2://localhost:10000/default> select key, symbol, `date`, high, low f ${dbname}.stocks_hbase limit 10;\n",
      "+------------------+---------+-------------+-------------+------------+\n",
      "|       key        | symbol  |    date     |    high     |    low     |\n",
      "+------------------+---------+-------------+-------------+------------+\n",
      "| 2000-07-18-INTC  | INTC    | 2000-07-18  | 144.828125  | 141.4375   |\n",
      "| 2000-07-20-BEN   | BEN     | 2000-07-20  | 34.25001    | 32.8125    |\n",
      "| 2000-07-24-APH   | APH     | 2000-07-24  | 67.312477   | 64.187523  |\n",
      "| 2000-07-26-SHW   | SHW     | 2000-07-26  | 22.125      | 20.9375    |\n",
      "| 2000-07-26-STJ   | STJ     | 2000-07-26  | 42.312481   | 41.625     |\n",
      "| 2000-07-31-GGP   | GGP     | 2000-07-31  | 33.999986   | 33.75      |\n",
      "| 2000-08-07-SBUX  | SBUX    | 2000-08-07  | 43.0        | 40.812481  |\n",
      "| 2000-08-09-EQT   | EQT     | 2000-08-09  | 55.625      | 54.5       |\n",
      "| 2000-08-10-BCR   | BCR     | 2000-08-10  | 52.625      | 48.75      |\n",
      "| 2000-08-15-BEN   | BEN     | 2000-08-15  | 35.68749    | 34.875     |\n",
      "+------------------+---------+-------------+-------------+------------+\n",
      "10 rows selected (0.932 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "mit 10;:hive2://localhost:10000/default> select * from ${dbname}.stocks_hbase li \n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+---------------------+----------------------+------------------------+----------------------+\n",
      "| stocks_hbase.key  | stocks_hbase.date  | stocks_hbase.open  | stocks_hbase.high  | stocks_hbase.low  | stocks_hbase.close  | stocks_hbase.volume  | stocks_hbase.adjclose  | stocks_hbase.symbol  |\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+---------------------+----------------------+------------------------+----------------------+\n",
      "| 2000-07-18-INTC   | 2000-07-18         | 144.8125           | 144.828125         | 141.4375          | 143.0               | 5.06836E7            | 50.155473              | INTC                 |\n",
      "| 2000-07-20-BEN    | 2000-07-20         | 32.93751           | 34.25001           | 32.8125           | 33.75               | 3288300.0            | 8.789734               | BEN                  |\n",
      "| 2000-07-24-APH    | 2000-07-24         | 64.25              | 67.312477          | 64.187523         | 64.75               | 948800.0             | 7.689567               | APH                  |\n",
      "| 2000-07-26-SHW    | 2000-07-26         | 21.875             | 22.125             | 20.9375           | 20.9375             | 1464300.0            | 15.61832               | SHW                  |\n",
      "| 2000-07-26-STJ    | 2000-07-26         | 42.0               | 42.312481          | 41.625            | 41.875              | 1397600.0            | 9.402721               | STJ                  |\n",
      "| 2000-07-31-GGP    | 2000-07-31         | 33.937519          | 33.999986          | 33.75             | 33.875011           | 273400.0             | 5.063753               | GGP                  |\n",
      "| 2000-08-07-SBUX   | 2000-08-07         | 41.375038          | 43.0               | 40.812481         | 42.812481           | 2.43376E7            | 4.869542               | SBUX                 |\n",
      "| 2000-08-09-EQT    | 2000-08-09         | 55.562481          | 55.625             | 54.5              | 55.0                | 387600.0             | 10.495977              | EQT                  |\n",
      "| 2000-08-10-BCR    | 2000-08-10         | 49.0               | 52.625             | 48.75             | 52.125              | 1511600.0            | 22.539051              | BCR                  |\n",
      "| 2000-08-15-BEN    | 2000-08-15         | 35.68749           | 35.68749           | 34.875            | 34.875              | 1246500.0            | 9.082726               | BEN                  |\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+---------------------+----------------------+------------------------+----------------------+\n",
      "10 rows selected (1.478 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "0: jdbc:hive2://localhost:10000/default> Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "# hive on hbase\n",
    "! pwd\n",
    "! ./run-hive.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab44ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
